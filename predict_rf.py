import os
import numpy as np
import gzip
from csv import reader, writer
from sklearn.ensemble import RandomForestClassifier
import six
import pickle

# Decide read/write mode based on python version
read_mode, write_mode = ('r','w') if six.PY2 else ('rt','wt')

# Decide zip based on python version
if six.PY2:
    from itertools import izip
    zp = izip
else:
    zp = zip

# Set path to your consolidated files
path = '/media/shreyansh/Seagate Backup Plus Drive/Data/Datasets/Malware Classification Dataset'
os.chdir(path)

# File names
ftest = 'test_consolidation.gz'
fsubmission = 'submission.gz'

# Load model
modelname = 'rf_vanilla_model.sav'
clf = pickle.load(open(modelname, 'rb'))
print("Model loaded!")

# Dimensions for test set
ntest = 10873
nfeature = 16**2 + 1 # For two_byte_codes, no_que_marks
test = np.zeros((ntest, nfeature), dtype = int)
Ids = []    # Required test set ids

with gzip.open(ftest, read_mode) as f:
    next(f)    # Ignoring header
    for t,row in enumerate(reader(f)):
        test[t,:] = map(int, row[1:]) if six.PY2 else list(map(int, row[1:]))
        Ids.append(row[0])
        if(t+1)%1000==0:
            print(t+1, 'records loaded')
print('Test set loaded')

# Predict for whole test set
y_pred = clf.predict_proba(test)

# Writing results to file
with gzip.open(fsubmission, write_mode) as f:
    fw = writer(f)
    # Header preparation
    header = ['Id'] + ['Prediction'+str(i) for i in range(1,10)]
    fw.writerow(header)
    for t, (Id, pred) in enumerate(zp(Ids, y_pred.tolist())):
        fw.writerow([Id]+pred)
        if(t+1)%1000==0:
            print(t+1, 'prediction written')
