import os
import numpy as np
import gzip
from csv import reader, writer
import six
import pickle
import xgboost
from xgboost import XGBClassifier

# Decide read/write mode based on python version
read_mode, write_mode = ('r','w') if six.PY2 else ('rt','wt')

# Decide zip based on python version
if six.PY2:
    from itertools import izip
    zp = izip
else:
    zp = zip

# Set path to your consolidated files
path = '/media/shreyansh/Seagate Backup Plus Drive/Data/Datasets/Malware Classification Dataset'
os.chdir(path)

# File names
ftrain = 'train_consolidation.gz'
flabel = 'trainLabels.csv'

print('loading started')
# Reading labels
labels = {}
with open(flabel) as f:
    next(f)    # Ignoring header
    for row in reader(f):
        labels[row[0]] = int(row[1])
print('labels loaded')

# Dimensions for train set
ntrain = 10868
nfeature = 16**2 + 1 + 1 # For two_byte_codes, no_que_marks, label
train = np.zeros((ntrain, nfeature), dtype = int)
with gzip.open(ftrain, read_mode) as f:
    next(f)    # Ignoring header
    for t,row in enumerate(reader(f)):
        train[t,:-1] = map(int, row[1:]) if six.PY2 else list(map(int, row[1:]))
        train[t,-1] = labels[row[0]]
        if(t+1)%1000==0:
            print(t+1, 'records loaded')
print('Training set loaded')

del labels

# Parameters for Randomforest
random_state = 123
n_jobs = 5
verbose = 2
xgb = XGBClassifier(
    learning_rate =0.1,
    n_estimators=500,
    max_depth=5,
    min_child_weight=1,
    gamma=0,
    subsample=0.8,
    colsample_bytree=0.8,
    objective= 'multi:softprob',
    nthread=4,
    scale_pos_weight=1,
    seed=27)

# Start training
print('Training started')
# -1 indicates the column with labels
xgb.fit(train[:,:-1], train[:,-1], eval_metric='mlogloss', verbose=True)
print('Training completed!')

# Saving model to disk
modelname = 'xgboost_model.sav'
pickle.dump(xgb, open(modelname, 'wb'))
print("Model saved!")

# Delete the training set
del train